{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Project 08 - Analysis of U.S. Immigration (I-94) Data\n",
    "### Udacity Data Engineer - Capstone Project\n",
    "> by Peter Wissel | 2021-05-05\n",
    "\n",
    "## Project Overview\n",
    "This project works with a data set for immigration to the United States. The supplementary datasets will include data on\n",
    "airport codes, U.S. city demographics and temperature data.\n",
    "\n",
    "The following process is divided into different sub-steps to illustrate how to answer the questions set by the business\n",
    "analytics team.\n",
    "\n",
    "The project file follows the following steps:\n",
    "* Step 4: Run ETL to Model the Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    "\n",
    "Run Quality Checks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 4.2.1 Define StructType and create result data frame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "###### Imports and Installs section\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import pyspark.sql.functions as F\n",
    "# import spark as spark\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType, StringType, IntegerType, LongType, TimestampType, DateType\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql import SparkSession, DataFrameNaFunctions\n",
    "from pyspark.sql.functions import when, count, col, to_date, datediff, date_format, month\n",
    "import re\n",
    "import json\n",
    "from os import path\n",
    "\n",
    "\n",
    "max_memory = \"5g\"\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"etl pipeline for project 8 - I94 data\") \\\n",
    "    .config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:3.0.0-s_2.12\")\\\n",
    "    .config('spark.sql.repl.eagerEval.enabled', True) \\\n",
    "    .config(\"spark.executor.memory\", max_memory) \\\n",
    "    .config(\"spark.driver.memory\", max_memory) \\\n",
    "    .appName(\"Foo\") \\\n",
    "    .enableHiveSupport()\\\n",
    "    .getOrCreate()\n",
    "\n",
    "# setting the current LOG-Level\n",
    "spark.sparkContext.setLogLevel('ERROR')\n",
    "\n",
    "# Define format to store data quality result data frame\n",
    "result_struct_type = StructType(\n",
    "    [\n",
    "         StructField(\"dq_result_table_name\", StringType(), True)\n",
    "        ,StructField(\"dq_result_null_entries\", IntegerType(), True)\n",
    "        ,StructField(\"dq_result_entries\", IntegerType(), True)\n",
    "        ,StructField(\"dq_result_status\", StringType(), True)\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# execute check commands"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#####  4.2.2 Data Quality (dq) checks for table d_immigration_countries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_dq_check_null_values: 0\n",
      "df_dq_check_content: 289\n"
     ]
    }
   ],
   "source": [
    "# read table table\n",
    "location_to_read = \"../P8_capstone_resource_files/parquet_star/PQ1/d_immigration_countries\"\n",
    "df_dq_table_d_immigration_countries = spark.read.parquet(location_to_read)\n",
    "\n",
    "# Check if key fields have valid values (no nulls or empty)\n",
    "df_dq_check_null_values = df_dq_table_d_immigration_countries \\\n",
    "    .select(\"d_ic_id\") \\\n",
    "    .where(\"d_ic_id is null or d_ic_id == ''\") \\\n",
    "    .count()\n",
    "\n",
    "print(f\"df_dq_check_null_values: {df_dq_check_null_values}\")\n",
    "\n",
    "# Check that table has > 0 rows\n",
    "df_dq_check_content = df_dq_table_d_immigration_countries.count()\n",
    "print(f\"df_dq_check_content: {df_dq_check_content}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "# insert result into result_df\n",
    "table_name = \"d_immigration_countries\"\n",
    "if df_dq_check_null_values < 1 and df_dq_check_content > 0:\n",
    "    dq_check_result = \"OK\"\n",
    "else:\n",
    "    dq_check_result = \"NOK\"\n",
    "\n",
    "print(dq_check_result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('d_immigration_countries', 0, 289, 'OK')]\n",
      "root\n",
      " |-- dq_result_table_name: string (nullable = true)\n",
      " |-- dq_result_null_entries: integer (nullable = true)\n",
      " |-- dq_result_entries: integer (nullable = true)\n",
      " |-- dq_result_status: string (nullable = true)\n",
      "\n",
      "+-----------------------+----------------------+-----------------+----------------+\n",
      "|dq_result_table_name   |dq_result_null_entries|dq_result_entries|dq_result_status|\n",
      "+-----------------------+----------------------+-----------------+----------------+\n",
      "|d_immigration_countries|0                     |289              |OK              |\n",
      "+-----------------------+----------------------+-----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dq_results = [ (table_name, df_dq_check_null_values, df_dq_check_content, dq_check_result) ]\n",
    "print(dq_results)\n",
    "\n",
    "# create results data frame\n",
    "df_dq_results = spark.createDataFrame(dq_results, result_struct_type)\n",
    "\n",
    "# check df schema and content\n",
    "df_dq_results.printSchema()\n",
    "df_dq_results.show(100, False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#####  4.2.3 Data Quality (dq) checks for table d_immigration_airports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_dq_check_null_values: 0\n",
      "df_dq_check_content: 660\n"
     ]
    }
   ],
   "source": [
    "# read table table\n",
    "location_to_read = \"../P8_capstone_resource_files/parquet_star/PQ2/d_immigration_airports\"\n",
    "df_dq_table_d_immigration_airports = spark.read.parquet(location_to_read)\n",
    "\n",
    "# Check if key fields have valid values (no nulls or empty)\n",
    "df_dq_check_null_values = df_dq_table_d_immigration_airports \\\n",
    "    .select(\"d_ia_id\") \\\n",
    "    .where(\"d_ia_id is null or d_ia_id == ''\") \\\n",
    "    .count()\n",
    "\n",
    "# Check that table has > 0 rows\n",
    "df_dq_check_content = df_dq_table_d_immigration_airports.count()\n",
    "\n",
    "print(f\"df_dq_check_null_values: {df_dq_check_null_values}\")\n",
    "print(f\"df_dq_check_content: {df_dq_check_content}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table_name: d_immigration_airports\n",
      "dq_check_result: OK\n",
      "df_dq_check_null_values: 0\n",
      "df_dq_check_content: 660\n"
     ]
    }
   ],
   "source": [
    "# insert result into result_df\n",
    "table_name = \"d_immigration_airports\"\n",
    "if df_dq_check_null_values < 1 and df_dq_check_content > 0:\n",
    "    dq_check_result = \"OK\"\n",
    "else:\n",
    "    dq_check_result = \"NOK\"\n",
    "\n",
    "print(f\"table_name: {table_name}\")\n",
    "print(f\"dq_check_result: {dq_check_result}\")\n",
    "print(f\"df_dq_check_null_values: {df_dq_check_null_values}\")\n",
    "print(f\"df_dq_check_content: {df_dq_check_content}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('d_immigration_airports', 0, 660, 'OK')]\n"
     ]
    }
   ],
   "source": [
    "dq_results = [\n",
    "    (table_name, df_dq_check_null_values, df_dq_check_content, dq_check_result)\n",
    "]\n",
    "print(dq_results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# add new row to current results data frame\n",
    "new_row = spark.createDataFrame(dq_results, result_struct_type)\n",
    "df_dq_results = df_dq_results.union(new_row)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+----------------------+-----------------+----------------+\n",
      "|dq_result_table_name   |dq_result_null_entries|dq_result_entries|dq_result_status|\n",
      "+-----------------------+----------------------+-----------------+----------------+\n",
      "|d_immigration_countries|0                     |289              |OK              |\n",
      "|d_immigration_airports |0                     |660              |OK              |\n",
      "+-----------------------+----------------------+-----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dq_results.show(10, False)\n",
    "\n",
    "##------------------------------------------------------------------------#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#####  4.2.4 Data Quality (dq) checks for table d_date_arrivals"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# read table table\n",
    "location_to_read = \"../P8_capstone_resource_files/parquet_star/PQ3/d_date_arrivals\"\n",
    "df_dq_table_d_date_arrivals = spark.read.parquet(location_to_read)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_dq_check_null_values: 0\n",
      "df_dq_check_content: 366\n"
     ]
    }
   ],
   "source": [
    "# Check if key fields have valid values (no nulls or empty)\n",
    "df_dq_check_null_values = df_dq_table_d_date_arrivals \\\n",
    "    .select(\"d_da_id\") \\\n",
    "    .where(\"d_da_id is null or d_da_id == ''\") \\\n",
    "    .count()\n",
    "\n",
    "# Check that table has > 0 rows\n",
    "df_dq_check_content = df_dq_table_d_date_arrivals.count()\n",
    "\n",
    "print(f\"df_dq_check_null_values: {df_dq_check_null_values}\")\n",
    "print(f\"df_dq_check_content: {df_dq_check_content}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table_name: d_date_arrivals\n",
      "dq_check_result: OK\n",
      "df_dq_check_null_values: 0\n",
      "df_dq_check_content: 366\n"
     ]
    }
   ],
   "source": [
    "# insert result into result_df\n",
    "table_name = \"d_date_arrivals\"\n",
    "if df_dq_check_null_values < 1 and df_dq_check_content > 0:\n",
    "    dq_check_result = \"OK\"\n",
    "else:\n",
    "    dq_check_result = \"NOK\"\n",
    "\n",
    "print(f\"table_name: {table_name}\")\n",
    "print(f\"dq_check_result: {dq_check_result}\")\n",
    "print(f\"df_dq_check_null_values: {df_dq_check_null_values}\")\n",
    "print(f\"df_dq_check_content: {df_dq_check_content}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('d_date_arrivals', 0, 366, 'OK')]\n"
     ]
    }
   ],
   "source": [
    "dq_results = [\n",
    "    (table_name, df_dq_check_null_values, df_dq_check_content, dq_check_result)\n",
    "]\n",
    "print(dq_results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# add new row to current results data frame\n",
    "new_row = spark.createDataFrame(dq_results, result_struct_type)\n",
    "df_dq_results = df_dq_results.union(new_row)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+----------------------+-----------------+----------------+\n",
      "|dq_result_table_name   |dq_result_null_entries|dq_result_entries|dq_result_status|\n",
      "+-----------------------+----------------------+-----------------+----------------+\n",
      "|d_immigration_countries|0                     |289              |OK              |\n",
      "|d_immigration_airports |0                     |660              |OK              |\n",
      "|d_date_arrivals        |0                     |366              |OK              |\n",
      "+-----------------------+----------------------+-----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dq_results.show(10, False)\n",
    "\n",
    "##------------------------------------------------------------------------#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#####  4.2.5 Data Quality (dq) checks for table d_date_departures"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# read table table\n",
    "location_to_read = \"../P8_capstone_resource_files/parquet_star/PQ3/d_date_departures\"\n",
    "df_dq_table_d_date_departures = spark.read.parquet(location_to_read)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_dq_check_null_values: 0\n",
      "df_dq_check_content: 531\n"
     ]
    }
   ],
   "source": [
    "# Check if key fields have valid values (no nulls or empty)\n",
    "df_dq_check_null_values = df_dq_table_d_date_departures \\\n",
    "    .select(\"d_dd_id\") \\\n",
    "    .where(\"d_dd_id is null or d_dd_id == ''\") \\\n",
    "    .count()\n",
    "\n",
    "# Check that table has > 0 rows\n",
    "df_dq_check_content = df_dq_table_d_date_departures.count()\n",
    "\n",
    "print(f\"df_dq_check_null_values: {df_dq_check_null_values}\")\n",
    "print(f\"df_dq_check_content: {df_dq_check_content}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table_name: d_date_departures\n",
      "dq_check_result: OK\n",
      "df_dq_check_null_values: 0\n",
      "df_dq_check_content: 531\n"
     ]
    }
   ],
   "source": [
    "# insert result into result_df\n",
    "table_name = \"d_date_departures\"\n",
    "if df_dq_check_null_values < 1 and df_dq_check_content > 0:\n",
    "    dq_check_result = \"OK\"\n",
    "else:\n",
    "    dq_check_result = \"NOK\"\n",
    "\n",
    "print(f\"table_name: {table_name}\")\n",
    "print(f\"dq_check_result: {dq_check_result}\")\n",
    "print(f\"df_dq_check_null_values: {df_dq_check_null_values}\")\n",
    "print(f\"df_dq_check_content: {df_dq_check_content}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('d_date_departures', 0, 531, 'OK')]\n"
     ]
    }
   ],
   "source": [
    "dq_results = [\n",
    "    (table_name, df_dq_check_null_values, df_dq_check_content, dq_check_result)\n",
    "]\n",
    "print(dq_results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# add new row to current results data frame\n",
    "new_row = spark.createDataFrame(dq_results, result_struct_type)\n",
    "df_dq_results = df_dq_results.union(new_row)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+----------------------+-----------------+----------------+\n",
      "|dq_result_table_name   |dq_result_null_entries|dq_result_entries|dq_result_status|\n",
      "+-----------------------+----------------------+-----------------+----------------+\n",
      "|d_immigration_countries|0                     |289              |OK              |\n",
      "|d_immigration_airports |0                     |660              |OK              |\n",
      "|d_date_arrivals        |0                     |366              |OK              |\n",
      "|d_date_departures      |0                     |531              |OK              |\n",
      "+-----------------------+----------------------+-----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dq_results.show(10, False)\n",
    "\n",
    "##------------------------------------------------------------------------#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#####  4.2.6 Data Quality (dq) checks for table d_state_destinations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# read table table\n",
    "location_to_read = \"../P8_capstone_resource_files/parquet_star/PQ4/d_state_destinations\"\n",
    "df_dq_table_d_state_destinations = spark.read.parquet(location_to_read)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_dq_check_null_values: 0\n",
      "df_dq_check_content: 55\n"
     ]
    }
   ],
   "source": [
    "# Check if key fields have valid values (no nulls or empty)\n",
    "df_dq_check_null_values = df_dq_table_d_state_destinations \\\n",
    "    .select(\"d_sd_id\") \\\n",
    "    .where(\"d_sd_id is null or d_sd_id == ''\") \\\n",
    "    .count()\n",
    "\n",
    "# Check that table has > 0 rows\n",
    "df_dq_check_content = df_dq_table_d_state_destinations.count()\n",
    "\n",
    "print(f\"df_dq_check_null_values: {df_dq_check_null_values}\")\n",
    "print(f\"df_dq_check_content: {df_dq_check_content}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table_name: d_state_destinations\n",
      "dq_check_result: OK\n",
      "df_dq_check_null_values: 0\n",
      "df_dq_check_content: 55\n"
     ]
    }
   ],
   "source": [
    "# insert result into result_df\n",
    "table_name = \"d_state_destinations\"\n",
    "if df_dq_check_null_values < 1 and df_dq_check_content > 0:\n",
    "    dq_check_result = \"OK\"\n",
    "else:\n",
    "    dq_check_result = \"NOK\"\n",
    "\n",
    "print(f\"table_name: {table_name}\")\n",
    "print(f\"dq_check_result: {dq_check_result}\")\n",
    "print(f\"df_dq_check_null_values: {df_dq_check_null_values}\")\n",
    "print(f\"df_dq_check_content: {df_dq_check_content}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('d_state_destinations', 0, 55, 'OK')]\n"
     ]
    }
   ],
   "source": [
    "dq_results = [\n",
    "    (table_name, df_dq_check_null_values, df_dq_check_content, dq_check_result)\n",
    "]\n",
    "print(dq_results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# add new row to current results data frame\n",
    "new_row = spark.createDataFrame(dq_results, result_struct_type)\n",
    "df_dq_results = df_dq_results.union(new_row)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+----------------------+-----------------+----------------+\n",
      "|dq_result_table_name   |dq_result_null_entries|dq_result_entries|dq_result_status|\n",
      "+-----------------------+----------------------+-----------------+----------------+\n",
      "|d_immigration_countries|0                     |289              |OK              |\n",
      "|d_immigration_airports |0                     |660              |OK              |\n",
      "|d_date_arrivals        |0                     |366              |OK              |\n",
      "|d_date_departures      |0                     |531              |OK              |\n",
      "|d_state_destinations   |0                     |55               |OK              |\n",
      "+-----------------------+----------------------+-----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dq_results.show(10, False)\n",
    "\n",
    "##------------------------------------------------------------------------#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#####  4.2.7 Data Quality (dq) checks for table f_i94_immigrations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# read table table\n",
    "location_to_read = \"../P8_capstone_resource_files/parquet_star/PQ4/f_i94_immigrations\"\n",
    "df_dq_table_f_i94_immigrations = spark.read.parquet(location_to_read)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# Check if key fields have valid values (no nulls or empty)\n",
    "df_dq_check_null_values = df_dq_table_f_i94_immigrations \\\n",
    "    .select(  \"f_i94_id\"\n",
    "            , \"d_ia_id\"\n",
    "            , \"d_sd_id\"\n",
    "            , \"d_da_id\"\n",
    "            , \"d_dd_id\"\n",
    "            , \"d_ic_id\"\n",
    "            ) \\\n",
    "    .where(  \"    f_i94_id is null or f_i94_id == ''\"\n",
    "             \" or d_ia_id is null or d_ia_id == ''\"\n",
    "             \" or d_sd_id is null or d_sd_id == ''\"\n",
    "             \" or d_da_id is null or d_da_id == ''\"\n",
    "             \" or d_dd_id is null or d_dd_id == ''\"\n",
    "             \" or d_ic_id is null or d_ic_id == ''\") \\\n",
    "    .count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_dq_check_null_values: 0\n",
      "df_dq_check_content: 12228839\n"
     ]
    }
   ],
   "source": [
    "# Check that table has > 0 rows\n",
    "df_dq_check_content = df_dq_table_f_i94_immigrations.count()\n",
    "\n",
    "print(f\"df_dq_check_null_values: {df_dq_check_null_values}\")\n",
    "print(f\"df_dq_check_content: {df_dq_check_content}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table_name: f_i94_immigrations\n",
      "dq_check_result: OK\n",
      "df_dq_check_null_values: 0\n",
      "df_dq_check_content: 12228839\n"
     ]
    }
   ],
   "source": [
    "# insert result into result_df\n",
    "table_name = \"f_i94_immigrations\"\n",
    "if df_dq_check_null_values < 1 and df_dq_check_content > 0:\n",
    "    dq_check_result = \"OK\"\n",
    "else:\n",
    "    dq_check_result = \"NOK\"\n",
    "\n",
    "print(f\"table_name: {table_name}\")\n",
    "print(f\"dq_check_result: {dq_check_result}\")\n",
    "print(f\"df_dq_check_null_values: {df_dq_check_null_values}\")\n",
    "print(f\"df_dq_check_content: {df_dq_check_content}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('f_i94_immigrations', 0, 12228839, 'OK')]\n"
     ]
    }
   ],
   "source": [
    "dq_results = [\n",
    "    (table_name, df_dq_check_null_values, df_dq_check_content, dq_check_result)\n",
    "]\n",
    "print(dq_results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# add new row to current results data frame\n",
    "new_row = spark.createDataFrame(dq_results, result_struct_type)\n",
    "df_dq_results = df_dq_results.union(new_row)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+----------------------+-----------------+----------------+\n",
      "|dq_result_table_name   |dq_result_null_entries|dq_result_entries|dq_result_status|\n",
      "+-----------------------+----------------------+-----------------+----------------+\n",
      "|d_immigration_countries|0                     |289              |OK              |\n",
      "|d_immigration_airports |0                     |660              |OK              |\n",
      "|d_date_arrivals        |0                     |366              |OK              |\n",
      "|d_date_departures      |0                     |531              |OK              |\n",
      "|d_state_destinations   |0                     |55               |OK              |\n",
      "|f_i94_immigrations     |0                     |12228839         |OK              |\n",
      "+-----------------------+----------------------+-----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dq_results.show(10, False)\n",
    "##------------------------------------------------------------------------#\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}